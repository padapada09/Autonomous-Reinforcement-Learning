{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color: #2b74af; font-size: 40px; background: lightBlue; padding: 15px; border-radius: 15px; box-shadow: 4px 4px 4px dark\">Librerías</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color: #2b74af; font-size: 40px; background: lightBlue; padding: 15px; border-radius: 15px; box-shadow: 4px 4px 4px dark\">Funciones útiles</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lastProm(array, amount):\n",
    "    suma = 0\n",
    "    last = array.__len__()\n",
    "    if last == 0:\n",
    "        return 0\n",
    "    if last < amount:\n",
    "        for x in array:\n",
    "            suma += x\n",
    "        return suma/(last)\n",
    "    for x in range(amount):\n",
    "        suma += array[last-(x+1)]\n",
    "    return suma/amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color: #2b74af; font-size: 40px; background: lightBlue; padding: 15px; border-radius: 15px; box-shadow: 4px 4px 4px dark\">Clase</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><h1>La clase toma como parametros posibles:</h1>\n",
    "    \n",
    "- Estados en los que existirá el agente\n",
    "- Tamaño de discretización (de cada estado por separado)\n",
    "- Hiperparametros epsilon, alpha, gamma.\n",
    "- \"epsilonDecay\" y \"alphaDecay\" son los epsilon y alpha finales. (Una vez que el agente logra la recompenza objetivo)\n",
    "- La recompenza esperada\n",
    "- \"continues\" es una variable booleana para indicar si el ambiente del agente es de estados continuos o discretos.\n",
    "- Los valores minimos y máximos de cada estado del agente.\n",
    "- \"auto\" es para determinar si el agente debe setear sus hiperparametros (alpha, epsilon, adecay y edecay) de manera automatica (actualmente los selecciona al azar).\n",
    "\n",
    "Además, la clase tiene un arreglo \"*memory*\" en la que puede almacenar el puntaje obtenido con una configuración automática de hiperparametros. (Mi idea es posteriormente usar esto para empezar a aplicar metodos de optimización de hiperparametros).\n",
    "\n",
    "En la inicialización o construcción de la clase, el agente crea una matriz \"policy\" con todos valores cero.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "\n",
    "    def __init__(self,state,posibleActions,sampleSize = [],epsilon = 0,alpha = 0,gamma = 0,epsilonDecay = 0,\n",
    "        alphaDecay = 0, expectedReturn = 0, continues = False, minimum = [], maximum = [], auto = False):\n",
    "        self.state = state\n",
    "        self.actions = posibleActions\n",
    "        self.sampleSize = sampleSize\n",
    "        self.epsilon = 1 - epsilon\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilonDecay = epsilonDecay\n",
    "        self.alphaDecay = alphaDecay\n",
    "        self.policy = self.initializePolicy(state,posibleActions,sampleSize)\n",
    "        self.continues = continues\n",
    "        self.minimum = minimum\n",
    "        self.maximum = maximum\n",
    "        self.record = []\n",
    "        self.expectedReturn = expectedReturn\n",
    "        self.alphaOriginal = alpha\n",
    "        self.epsilonOriginal = epsilon\n",
    "        if (auto):\n",
    "            self.memory = []\n",
    "            self.alpha = random.random()*1\n",
    "            self.alphaOriginal = self.alpha\n",
    "            self.epsilon = random.random()*1\n",
    "            self.epsilonOriginal = self.epsilon\n",
    "            self.epsilonDecay = random.random()*1\n",
    "            self.alphaDecay = random.random()*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "    <h1>Función \"decide\"</h1>\n",
    "    \n",
    "   La clase tiene un metodo en el que tomará decisiones dado el estado en el que se encuentre al tomar la decisión (no toma parametros). Para la exploración y explotación se utiliza una función \"*softmax*\": $$P(a)= \\frac{e^{\\alpha Q(a|s)}} {\\sum_{i=0}^{i=j} e^{\\alpha Q(i|s)}} \\iff j = posibeActions$$\n",
    "   \n",
    "   Esta función lo que hace es tomar un vector y procesarlo de manera que su modulo sea igual a uno. Luego según que tan grande sea cada parametro del vector, le damos una probabilidad a cada acción de que suceda. El parametro alpha se usa para poder variar el nivel de exploración y/o explotación. Notese que cuando alpha es igual a cero, todos los valores del vector tendrán igual magnitud, es decir, tendremos exploración pura. Por el contrario, a medida que alpha se hace mas grande, conseguimos tender más a la explotación.\n",
    "   \n",
    "   Por último, en el algoritmo se le resta a Q(a|s) el max[Q(s)] para normalizar la función y evitar problemas de overflow.\n",
    "   </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def decide(self):\n",
    "        inputs = self.policy[tuple(self.state)]\n",
    "        probability0 = np.exp((inputs-np.amax(inputs))*self.epsilon) / float(sum(np.exp((inputs-np.amax(inputs))*self.epsilon)))\n",
    "        probability1 = np.exp((inputs-np.amax(inputs))*self.epsilon) / float(sum(np.exp((inputs-np.amax(inputs))*self.epsilon)))\n",
    "        probability1.sort()\n",
    "        chance = 0\n",
    "        posibility = random.random()\n",
    "        for action in probability1:\n",
    "            chance += action\n",
    "            if chance > posibility:\n",
    "                return np.where(probability0 == action)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "    <h1>Función \"update\"</h1>\n",
    "    \n",
    "   Llamada cada vez que se termina un episodio, en la función update, el agente guarda en su memoria (\"record\") la recompenza obtenida en el episodio (pasada como parametro para la función), y actualiza los valores de alpha y epsilon según que tan cerca este de la recompenza esperada final. La actualización es lineal.\n",
    "   </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def update(self,reward):\n",
    "        if self.record.__len__() < 1:\n",
    "            self.rewardOffset = abs(reward - self.expectedReturn)\n",
    "        self.record.append(reward)\n",
    "        newAlpha = self.alphaOriginal * self.alphaDecay * (1/pow(self.alphaDecay, abs(lastProm(self.record, 200) - self.expectedReturn) / self.rewardOffset))\n",
    "        newEpsilon = self.epsilonOriginal * self.epsilonDecay * (1/pow(self.epsilonDecay, abs(lastProm(self.record, 200) - self.expectedReturn) / self.rewardOffset))\n",
    "        self.alpha = newAlpha\n",
    "        self.epsilon = newEpsilon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "    <h1>Función \"optimize\"</h1>\n",
    "    \n",
    "   Por el momento la función \"optimize\" simplemente selecciona al azar valores para los hiperparametros principales, y guarda en \"memory\" una recompenza promedio lograda con una configuración de hiperparametros especifica. Esta función, la imagino sin mayores cambios cuando se aplique optimización Bayesiana, pero seleccionando los nuevos valores según el grado de incertidumbre que tuvieramos en el modelo construido (Todavía el algoritmo no hace ningun modelo, pero es como imagino debería seguir el funcionamiento de la optimización).\n",
    "   </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def optimize(self, reward):\n",
    "        self.memory.append([reward, self.alphaOriginal, self.epsilonOriginal, self.alphaDecay, self.epsilonDecay])\n",
    "        self.alpha = random.random()\n",
    "        self.alphaOriginal = self.alpha\n",
    "        self.epsilon = random.random()\n",
    "        self.epsilonOriginal = self.epsilon\n",
    "        self.alphaDecay = random.random()\n",
    "        self.epsilonDecay = random.random()\n",
    "        self.policy = self.initializePolicy(self.state,self.actions,self.sampleSize)\n",
    "        self.record = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "    <h1>Función \"learn\"</h1>\n",
    "    \n",
    "   En esta función se aplica Q-learning, actualizando los valores de la matriz según dicho algoritmo:\n",
    "   $$Q(s_{t},a_{t}) = (1- \\alpha) \\cdot Q(s_{t},a_{t}) + \\alpha \\cdot [r_{t} + \\gamma \\cdot max_{Q(s_{t},a)}] $$\n",
    "   \n",
    "   Mi intención es aplicar \"n-step\" bootstraping para que pueda ser una parametro de configuración mas. Y también poder aplicar conceptos de redes neuronales para que el algoritmo también pueda usar el modelo de \"*Deep Q Learning*\".\n",
    "   </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def learn(self, newState, actionTaken, reward):\n",
    "        if self.continues:\n",
    "            newStatef = self.discretize(newState)\n",
    "        fullState = self.state\n",
    "        fullState.append(actionTaken)\n",
    "        old_value = self.policy[tuple(fullState)]\n",
    "        new_value = (1 - self.alpha) * old_value + self.alpha * (reward + self.gamma*(max(self.policy[tuple(newStatef)])))\n",
    "        self.policy[tuple(fullState)] = new_value\n",
    "        self.setState(newState)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "    <h1>Función \"initializePolicy\"</h1>\n",
    "    \n",
    "   Función en la que inicializo la politica del agente dado un array de estados posibles, un array de acciones posibles y un tamaño de muestreo en los que son divididos los estados. Lo mas interesante de la función, y tambien del algoritmo en su conjunto, es que toma arrays de multiples dimensiones, por lo que el agente se puede adaptar con relativa facilidad a ambientes en los que tenga que atender diversas cantidades de estados (Siendo limite la capacidad de procesamiento disponible).\n",
    "   </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def initializePolicy(self,states,actions,sampleSize):\n",
    "        array = []\n",
    "        for state in range(states.__len__()):\n",
    "            array.append(sampleSize[state])\n",
    "        array.append(actions.__len__())\n",
    "        policy = np.zeros(array)\n",
    "        return policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "    <h1>Función \"discretize\"</h1>\n",
    "    \n",
    "   Para poder adaptarse a ambientes continuos, el agente tiene una función con la que discretize el estado dado por el entorno, y lo mapea según el muestreo, y los valores máximos y mínimos, especificados en la construcción del agente.\n",
    "   </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def discretize(self, states):\n",
    "        j = -1\n",
    "        discreteState = []\n",
    "        for state in states:\n",
    "            j += 1\n",
    "            increment = (abs(self.minimum[j])+self.maximum[j])/self.sampleSize[j]\n",
    "            for i in range(0, self.sampleSize[j]):\n",
    "                if state < increment*(i+1) + self.minimum[j]:\n",
    "                    discreteState.append(i)\n",
    "                    break\n",
    "        return discreteState"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "    <h1>Función \"setState\"</h1>\n",
    "    \n",
    "   Una función para poder actualizar el estado en el que e encuentra el agente.\n",
    "   \n",
    "   Me pareció mas interesante que el agente puede moverse de estados y decidir posteriormente según el estado en el que se encuentre, que pasar el estado actual a la función \"decide\".\n",
    "   </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def setState(self,state):\n",
    "        if self.continues :\n",
    "            self.state = self.discretize(state)\n",
    "        if not(self.continues):\n",
    "            self.state = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent: 9 - Episode: 999 (alpha = 0.22 || epsilon = 0.18)  -> Score: 199.65\r"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import learning\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "states = [0,0,0,0]\n",
    "actions = [0,0]\n",
    "\n",
    "maximum = [2.5, 4, 0.8, 4]\n",
    "minimum = [-2.5, -4, -0.8,-4]\n",
    "\n",
    "episodes = 1000\n",
    "Intents = []\n",
    "\n",
    "for metaEpisode in range(10):\n",
    "    \n",
    "    rewards = []\n",
    "    \n",
    "    cart = learning.Agent(\n",
    "        state = states,\n",
    "        sampleSize = [10,1,30,30],\n",
    "        posibleActions = actions,\n",
    "        epsilon = 0.149862682,\n",
    "        alpha = 0.818792154792417,\n",
    "        gamma = 1,\n",
    "        epsilonDecay = 1.18220248060764,\n",
    "        alphaDecay = 0.268458061557817,\n",
    "        expectedReturn = 200,\n",
    "        continues = True,\n",
    "        maximum = maximum,\n",
    "        minimum = minimum\n",
    "        )\n",
    "\n",
    "    for episode in range(episodes):\n",
    "\n",
    "        observation = env.reset()\n",
    "        episodeReward = 0\n",
    "        cart.setState(observation)\n",
    "\n",
    "        for step in range(200):\n",
    "                \n",
    "            action = cart.decide()\n",
    "            \n",
    "            observation, reward, done, info = env.step(action)\n",
    "\n",
    "            episodeReward += reward\n",
    "\n",
    "            cart.learn(observation,action,reward)\n",
    "\n",
    "            if done:\n",
    "                rewards.append(episodeReward)\n",
    "                cart.update(episodeReward)\n",
    "                print (\"Intent: \" + str(metaEpisode) + \" - Episode: \" + str(episode) + \" (alpha = \"+ str(round(cart.alpha,2)) +\" || epsilon = \" + str(round(cart.epsilon,2)) + \")  -> Score: \" + str(round(lastProm(cart.record,100),2)), end=\"\\r\")\n",
    "                episodeReward = 0\n",
    "                break\n",
    "\n",
    "    Intents.append(rewards)\n",
    "\n",
    "plt.plot(np.mean(Intents, axis=0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
